{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Criteo Uplift v2.1 â€” Exploratory Analysis\n",
        "\n",
        "This notebook assumes the raw CSV has been converted to Parquet using the standalone script, then performs EDA: schema, missingness, treatment/control balance, outcome rates, and baseline uplift.\n",
        "\n",
        "Data paths:\n",
        "- Parquet: `./data/criteo-uplift-v2.1.parquet`\n",
        "\n",
        "Prerequisite:\n",
        "- Run: `python src/etl/prepare_dataset.py data/criteo-uplift-v2.1.csv data/criteo-uplift-v2.1.parquet --chunksize 1000000`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import json\n",
        "import math\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "CSV_PATH = \"/home/andres/Documents/uplift-modeling/data/criteo-uplift-v2.1.csv\"\n",
        "PARQUET_PATH = \"/home/andres/Documents/uplift-modeling/data/criteo-uplift-v2.1.parquet\"\n",
        "\n",
        "print({\"pandas\": pd.__version__, \"numpy\": np.__version__})\n",
        "print({\"csv_exists\": os.path.exists(CSV_PATH)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data availability check\n",
        "\n",
        "if not os.path.exists(PARQUET_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        \"Parquet not found. Please run the standalone converter: \\n\"\n",
        "        \"python src/etl/prepare_dataset.py data/criteo-uplift-v2.1.csv data/criteo-uplift-v2.1.parquet --chunksize 1000000\"\n",
        "    )\n",
        "else:\n",
        "    print({\"parquet_found\": True, \"path\": PARQUET_PATH})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Parquet (required)\n",
        "\n",
        "df = pd.read_parquet(PARQUET_PATH)\n",
        "print({\"loaded\": \"parquet\", \"rows\": len(df), \"cols\": len(df.columns)})\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Schema and Missingness\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "# Memory footprint\n",
        "mem_mb = df.memory_usage(deep=True).sum() / (1024**2)\n",
        "print({\"memory_mb\": round(mem_mb, 2)})\n",
        "\n",
        "# Missingness summary\n",
        "nulls = df.isna().sum().sort_values(ascending=False)\n",
        "nulls_pct = (nulls / len(df) * 100).round(2)\n",
        "missing_df = pd.DataFrame({\"missing\": nulls, \"missing_pct\": nulls_pct})\n",
        "missing_df.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heuristic detection for treatment and outcome columns\n",
        "\n",
        "from typing import Tuple\n",
        "\n",
        "def detect_treatment_outcome(columns: List[str]) -> Tuple[Optional[str], Optional[str]]:\n",
        "    lower = [c.lower() for c in columns]\n",
        "    treat_aliases = [\"treatment\", \"treat\", \"exposure\", \"variant\", \"w\", \"trt\", \"test\"]\n",
        "    outcome_aliases = [\"conversion\", \"converted\", \"label\", \"y\", \"response\", \"target\", \"purchase\"]\n",
        "\n",
        "    treatment = None\n",
        "    outcome = None\n",
        "\n",
        "    for alias in treat_aliases:\n",
        "        for c in columns:\n",
        "            if alias in c.lower():\n",
        "                treatment = c\n",
        "                break\n",
        "        if treatment:\n",
        "            break\n",
        "\n",
        "    for alias in outcome_aliases:\n",
        "        for c in columns:\n",
        "            if alias in c.lower():\n",
        "                outcome = c\n",
        "                break\n",
        "        if outcome:\n",
        "            break\n",
        "\n",
        "    return treatment, outcome\n",
        "\n",
        "tr_col, y_col = detect_treatment_outcome(df.columns.tolist())\n",
        "print({\"treatment_col\": tr_col, \"outcome_col\": y_col})\n",
        "\n",
        "# If not found, try common Criteo naming\n",
        "if tr_col is None:\n",
        "    for c in df.columns:\n",
        "        if c.lower() in [\"treatment\", \"treatment_group\", \"exposed\", \"exposure\", \"variant\"]:\n",
        "            tr_col = c\n",
        "            break\n",
        "if y_col is None:\n",
        "    for c in df.columns:\n",
        "        if c.lower() in [\"conversion\", \"response\", \"label\", \"y\", \"visit\", \"visit_binary\", \"conversion_binary\"]:\n",
        "            y_col = c\n",
        "            break\n",
        "\n",
        "print({\"final_treatment_col\": tr_col, \"final_outcome_col\": y_col})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline uplift (difference in means) and CI\n",
        "\n",
        "import math\n",
        "\n",
        "if tr_col is None or y_col is None:\n",
        "    raise ValueError(\"Could not detect treatment/outcome columns automatically. Please set `tr_col` and `y_col`.\")\n",
        "\n",
        "# Ensure numeric/binary\n",
        "outcome = pd.to_numeric(df[y_col], errors=\"coerce\")\n",
        "tr = pd.to_numeric(df[tr_col], errors=\"coerce\")\n",
        "\n",
        "mask = (~outcome.isna()) & (~tr.isna())\n",
        "outcome = outcome[mask]\n",
        "tr = tr[mask]\n",
        "\n",
        "# Binariaze if needed (assume >0 means positive)\n",
        "if sorted(outcome.unique()) not in ([0,1], [0.0,1.0]):\n",
        "    outcome = (outcome > 0).astype(int)\n",
        "\n",
        "tr = (tr > 0).astype(int)\n",
        "\n",
        "p_treat = outcome[tr == 1].mean()\n",
        "p_ctrl = outcome[tr == 0].mean()\n",
        "uplift = p_treat - p_ctrl\n",
        "\n",
        "# Wald CI for difference in proportions\n",
        "n_t = (tr == 1).sum()\n",
        "n_c = (tr == 0).sum()\n",
        "se = math.sqrt(p_treat*(1-p_treat)/n_t + p_ctrl*(1-p_ctrl)/n_c)\n",
        "z = 1.96\n",
        "ci_low = uplift - z * se\n",
        "ci_high = uplift + z * se\n",
        "\n",
        "print({\n",
        "    \"n_treat\": int(n_t),\n",
        "    \"n_control\": int(n_c),\n",
        "    \"p_treat\": round(p_treat, 6),\n",
        "    \"p_control\": round(p_ctrl, 6),\n",
        "    \"uplift\": round(uplift, 6),\n",
        "    \"ci95\": (round(ci_low, 6), round(ci_high, 6))\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple plots: treatment balance and outcome rates\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "\n",
        "sns.countplot(x=tr, ax=axes[0])\n",
        "axes[0].set_title(\"Treatment assignment counts\")\n",
        "axes[0].set_xlabel(\"treatment (0/1)\")\n",
        "\n",
        "rates = pd.DataFrame({\n",
        "    \"group\": [\"control\", \"treatment\"],\n",
        "    \"rate\": [p_ctrl, p_treat]\n",
        "})\n",
        "sns.barplot(data=rates, x=\"group\", y=\"rate\", ax=axes[1])\n",
        "axes[1].set_title(\"Outcome rate by group\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: feature distribution snapshots (top-K columns)\n",
        "\n",
        "K = 10\n",
        "num_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c not in {tr_col, y_col}][:K]\n",
        "cat_cols = [c for c in df.select_dtypes(exclude=[np.number]).columns][:K]\n",
        "\n",
        "fig, axes = plt.subplots(len(num_cols), 2, figsize=(10, 4*len(num_cols))) if num_cols else (None, None)\n",
        "if num_cols:\n",
        "    for i, c in enumerate(num_cols):\n",
        "        sns.histplot(df[c], bins=50, ax=axes[i,0])\n",
        "        axes[i,0].set_title(f\"{c} distribution\")\n",
        "        sns.boxplot(x=df[c], ax=axes[i,1])\n",
        "        axes[i,1].set_title(f\"{c} boxplot\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if cat_cols:\n",
        "    for c in cat_cols:\n",
        "        plt.figure(figsize=(8,3))\n",
        "        vc = df[c].astype(str).value_counts().head(20)\n",
        "        sns.barplot(x=vc.values, y=vc.index)\n",
        "        plt.title(f\"Top categories for {c}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
